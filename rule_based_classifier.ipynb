{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d0ebc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasify (x:str)->str:\n",
    "    s_key=[\"cricket\",\"Football\",\"volibll\"]\n",
    "    if any(key in x for key in s_key):\n",
    "        return \"sports\"\n",
    "    else:\n",
    "        return \"Other\"\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d85b2705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Other\n"
     ]
    }
   ],
   "source": [
    "t=clasify(\"nahid\")\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7375a374",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(x: str) -> dict[str, float]:\n",
    "    features = {}\n",
    "    x_split = x.split(' ')\n",
    "    \n",
    "    # Count the number of \"good words\" and \"bad words\" in the text\n",
    "    good_words = ['love', 'good', 'nice', 'great', 'enjoy', 'enjoyed']\n",
    "    bad_words = ['hate', 'bad', 'terrible', 'disappointing', 'sad', 'lost', 'angry','crass']\n",
    "    for x_word in x_split:\n",
    "        if x_word in good_words:\n",
    "            features['good_word_count'] = features.get('good_word_count', 0) + 1\n",
    "        if x_word in bad_words:\n",
    "            features['bad_word_count'] = features.get('bad_word_count', 0) + 1\n",
    "    \n",
    "    # The \"bias\" value is always one, to allow us to assign a \"default\" score to the text\n",
    "    features['bias'] = 1\n",
    "    \n",
    "    return features\n",
    "\n",
    "feature_weights = {'good_word_count': 1.0, 'bad_word_count': -1.0, 'bias': 0.5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ce90454d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_xy_data(filename: str) -> tuple[list[str], list[int]]:\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            label, text = line.strip().split(' ||| ')\n",
    "            x_data.append(text)\n",
    "            y_data.append(int(label))\n",
    "    return x_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d814d513",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = read_xy_data('Data/sst-sentiment-text-fiveclass/test.txt')\n",
    "x_test, y_test = read_xy_data('Data/sst-sentiment-text-fiveclass/dev.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5971ba34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emerges as something rare , an issue movie that 's so honest and keenly observed that it does n't feel like one .\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(x_train[2])\n",
    "print(y_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fdd7e47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_classifier(x: str) -> int:\n",
    "    score = 0\n",
    "    for feat_name, feat_value in extract_features(x).items():\n",
    "        score = score + feat_value * feature_weights.get(feat_name, 0)\n",
    "    if score > 0:\n",
    "        return 1\n",
    "    elif score < 0:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9cd2e8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(x_data: list[str], y_data: list[int]) -> float:\n",
    "    total_number = 0\n",
    "    correct_number = 0\n",
    "    for x, y in zip(x_data, y_data):\n",
    "        y_pred = run_classifier(x)\n",
    "        total_number += 1\n",
    "        if y == y_pred:\n",
    "            correct_number += 1\n",
    "    return correct_number / float(total_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dfb960fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{3: 279, 2: 229, 4: 165, 0: 139, 1: 289}\n"
     ]
    }
   ],
   "source": [
    "label_count = {}\n",
    "for y in y_test:\n",
    "    if y not in label_count:\n",
    "        label_count[y] = 0\n",
    "    label_count[y] += 1\n",
    "print(label_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "525719ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.27692307692307694\n",
      "Dev/test accuracy: 0.24977293369663942\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = calculate_accuracy(x_train, y_train)\n",
    "test_accuracy = calculate_accuracy(x_test, y_test)\n",
    "print(f'Train accuracy: {train_accuracy}')\n",
    "print(f'Dev/test accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b11cb99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def find_errors(x_data, y_data):\n",
    "    error_ids = []\n",
    "    y_preds = []\n",
    "    for i, (x, y) in enumerate(zip(x_data, y_data)):\n",
    "        y_preds.append(run_classifier(x))\n",
    "        if y != y_preds[-1]:\n",
    "            error_ids.append(i)\n",
    "    for _ in range(5):\n",
    "        my_id = random.choice(error_ids)\n",
    "        x, y, y_pred = x_data[my_id], y_data[my_id], y_preds[my_id]\n",
    "        print(f'{x}\\ntrue label: {y}\\npredicted label: {y_pred}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "568955a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This insightful , Oscar-nominated documentary , in which children on both sides of the ever-escalating conflict have their say away from watchful parental eyes , gives peace yet another chance .\n",
      "true label: 3\n",
      "predicted label: 1\n",
      "\n",
      "Subversive , meditative , clinical and poetic , The Piano Teacher is a daring work of genius .\n",
      "true label: 3\n",
      "predicted label: 1\n",
      "\n",
      "The long-range appeal of `` Minority Report '' should transcend any awards it bags .\n",
      "true label: 3\n",
      "predicted label: 1\n",
      "\n",
      "The result is something quite fresh and delightful .\n",
      "true label: 4\n",
      "predicted label: 1\n",
      "\n",
      "For Benigni it was n't Shakespeare whom he wanted to define his career with but Pinocchio .\n",
      "true label: 3\n",
      "predicted label: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "find_errors(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d3e128",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
